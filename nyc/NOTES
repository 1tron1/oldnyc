The NYC photos come from the NYPL's Milstein collection.

Start page:
http://digitalgallery.nypl.org/nypldigital/dgdivisionbrowseresult.cfm?div_id=hh

Matt K sent me a CSV file for their digitized photos with 43363 records.
(there are 63091 lines, but some records contain newlines)


Interesting fields:
 3	 59% (25721/43363)	CREATOR		Balgue, George L.--Photographer
 5	100% (43363/43363)	IMAGE_Permalink	http://digitalgallery.nypl.org/nypldigital/id?716312f
 6	100% (43363/43363)	DIGITAL_ID	716312f
11	100% (43363/43363)	RECORD_ID	406110
12	 62% (26943/43363)	Borough		Manhattan
13	 73% (31674/43363)	Address		??Amsterdam Avenue & La Salle Street
14	 84% (36327/43363)	Full Address	??Amsterdam Avenue & La Salle Street, Manhattan, NY
15	100% (43363/43363)	IMAGE_TITLE	??Manhattan: Amsterdam Avenue - La Salle Street
16	100% (43363/43363)	IMG_URL		http://images.nypl.org/index.php?id=716312f&t=w
17	 64% (27648/43363)	CREATED_DATE	1927

Other fields are rare or identical across all records.

Borough field breakdown:
  18084 Manhattan
  16420 ""
   5391 Brooklyn
   2253 Bronx
    845 ", Manhattan"
    257 Queens
    108 Staten Island
      3 Newtown Creek
      2 Governor's Island

Dates breakdown:
     1 1790's
     2 1820's
     5 1830's
    11 1850's
    69 1860's
    99 1870's
   149 1880's
   480 1890's
  1027 1900's
  1360 1910's
  6251 1920's
 10754 1930's
  2011 1940's
    30 1950's
    61 1960's
    28 1970's

My OldSF date range parser is able to understand 23375/25721=91% of the
date ranges.

About 75% of the images are from 1920-1949.

Date oddities:
This record is listed (in the CSV) as being created on "14793": http://digitalgallery.nypl.org/nypldigital/dgkeysearchdetail.cfm?strucID=288071&imageID=485982



Stuff to ask Maira/Matt:
1. What's the deal with odd dates like "14793" in the spreadsheet?
2. Most (~75%) of photos from 1920-1950, does that seem right?
3. Easy to get metadata on image height/width?
4. What's the largest version of the image available online?
5. Any way to get at just the image (and not the scan of its brown backing paper)?
6. There are some images (e.g. http://digitalgallery.nypl.org/nypldigital/id?700631f or http://digitalgallery.nypl.org/nypldigital/id?717711f) where there's a description and date on the image, but not on the site. Any way to get that? Have they not been digitized?
7. Are there any pre-rendered thumbnails?
    -> &t=r instead of &t=w
8. OK if I serve images directly off the NYPL site? (I used AWS for OldSF)



----

I uploaded the image records for OldSF to AppEngine so long ago that I have no
idea how I did it. They may have gone through the image labeling game, so that
there's some path dependence.

I should verify that geocoded addresses are in the borough they claim to be.
All of the dots around Greenwood Cemetery should be in Manhattan:
http://localhost:8080/#ll:40.652937|-74.002161&m:40.65581|-73.98758|15


----

I asked the NYPL folks whether there were higher-resolution images available.
David Riordan sent out links to "MrSID" files which are available on their
servers. This is an incredibly obscure image format which is designed for easy
scaling (ala Google Maps tiles). For better or for worse, it's the format that
the Milstein images were scanned in.

There's a sample MrSID file at:
http://lt.images.nypl.org/lizardtech/iserv/getdoc?cat=NYPL&item=ED/EDAA/9A2E/8602/11DD/8103/6EC3/9956/CD/EDAA9A2E-8602-11DD-8103-6EC39956CD08.sid

One option to convert it is to use "gdal_translate" with MrSID enabled.
Instructions for building this:
http://trac.osgeo.org/gdal/wiki/MrSID
http://trac.osgeo.org/gdal/wiki/BuildingOnMac

I set up an account with LizardTech and downloaded their SDK.

The SDK includes a "mrsiddecode" tool which works great!

$ mrsiddecode -i nyc.sid -o nyc.jpg
(takes ~10 seconds to convert)

The 3.5M MrSID file converts to either a 1.3MB JPG or a 25MB PNG file.

To download all the MrSID files, I can...
1. Fetch http://images.nypl.org/index.php?id=(image id)&t=d
2. Parse the '&item=' field out of the URL it redirects to
3. Fetch http://lt.images.nypl.org/lizardtech/iserv/getdoc?cat=NYPL&item=(ITEM).sid

It takes ~10 s to fetch each image and ~10 seconds to convert them, so w/ 40k
images, each of these would take 4-5 days.

----

Detecting the "cards" inside the Milstein images is going to be tricky.
It seems like a good candidate for edge detection + hough transform.

brew install PIL
sudo /usr/bin/easy_install scipy
sudo /usr/bin/easy_install -U scikit-image
  (needs Cython)

After some hacking, it seems like this will be a good strategy:
1. Shrink the images 5x in each dimension
2. Run canny edge detection
3. Zero out the margins (40px on each side)
4. Threshold at half the Otsu threshold.
5. Calculate sums across each column and each row.
6. Differentiate these.
7. Pick out the top 10 x- & y-coords.
8. Build rectangles out of each of these. Pick the brightest one (in canny image)

Another idea:
Canny finds x- and y-edges, then combines them into edges at any angle. But I
really do want x- and y-edges! Maybe I can use this intermediate data.

Another idea:
Binarize based on "brownness".
-> This works great!


Random sample of ten images:
images/733251f.jpg + perfect (2 cards)
images/700043f.jpg - (detects the entire image; background is too light)
images/715405f.jpg / (detects one correctly, other is the full top-half)
images/711018f.jpg + perfect (1 card)
images/715240f.jpg + perfect (2 cards)
images/702532f.jpg - (detects the entire image; background is too light)
images/725010f.jpg + perfect (1 card)
images/715153f.jpg + perfect (1 card)
images/710534f.jpg + perfect (1 card)
images/715591f.jpg + perfect (1 card)

-> 70% correct on the first go!

Made one change:
Instead of hard-coding brown as (178, 137, 90), I set it as the median color of
the image.

images/733251f.jpg +
images/700043f.jpg +
images/715405f.jpg +
images/711018f.jpg +
images/715240f.jpg +
images/702532f.jpg +
images/725010f.jpg +
images/715153f.jpg +
images/710534f.jpg +
images/715591f.jpg +

!!! 100% !!!



images/715426f.jpg doesn't work correctly
images/711019f.jpg (four small images)
images/715238f.jpg (combines two close images)

-----
2013-02-24

I've fetched essentially all the photos whose digital_ids end in 'f'
(34580/34726). This is ~80% of all the photos.


For a 'f' image, the sequence begins with
http://images.nypl.org/index.php?id=(image_id)&t=d

but this fails for non-'f' images.

Only a small fraction of the non-'f' images are on brown cards.
Using '&t=w' works fine.
http://images.nypl.org/index.php?id=3978353&t=w

Many of these non-'f' images don't have a "Zoom" button on the NYPL site, which
I take to mean that they have no associated MrSid file. But the same sequence
does work for some, so I'll try to get what I can.

I used Local Turk to generate test data for 100 images.

What's a good scoring function? There are two levels of "right":
1. Getting the correct number of photos
2. Getting the correct positions of the photos


-----
2013-03-07

With help from StackOverflow, I'm using a more principled way of detecting
regions (modeled after Matlab's RegionProps method) and am using
ndimage.binary_fill_holes to patch things up in the binarized image.

>= 10 : 16 are perfect
>= 20 : 15 are perfect

For some images (717271f.jpg), reducing the threshold from 20 -> 10 makes all
the difference. Backing off might work, but how to know if you only have 2/3?

For others (1507735.jpg), lowering the 95% Solidity threshold to 90% makes all
the difference.

-----
2013-04-10

Goal is to come up with a program that can reliably either:
1. Correctly detect photos in an image
2. Decline to do anything

i.e. have very few false positives.

After some tweaking, I came up with something that has these stats on the 120
training images:

     Safe: 5 (0.0417)
  Correct: 113 (0.9417)
    Wrong: 2 (0.0167)

i.e. it partitions 94% correctly, takes a conservative pass on 4% and gets 1.7%
incorrect.

In this last category, one is because of a bad binarization (one
image becomes two). The other is because only 2/3 photos in an image are
detected (the third is sepia and, unlike the other two, doesn't have a white
border). These are both lame, but the former is lamer.

2013-04-13
Goals:
- Last tweaks to photo-finding algorithm.
- Run on 100-200 new random photos from the full collection.
- Take a crack at removing white borders.
- Kick off a run on the full set.

#26: pass, but shouldn't be?
#36: bad pass
#39: huge border!
#45: bad pass
#46: bad pass
#49: bad pass
#61: bad pass
#62: bad pass
#70: bad pass
#77: bad pass?

Setting a pass threshold in terms of solidity (instead of height/width
fraction) might make more sense.

Going over a second sample of 100 images.
-- lots more passes on this set --
8/100 images2/1596925.jpg -- false positive
14/100 (pass) images2/701333f.jpg -- bad pass

-> Looked really good!
-> The problems were almost all with the early images; maybe a different set?
  -> Fortunately, the really bad ones don't have addresses!

Cropping an image takes ~1s on my laptop.

Started on the full 40k run at 3:14PM.
... scratch that! My workstation has 12 cores, so why not run a few copies in parallel?
Restarted w/ four tasks at 3:22PM.

There were a few issues with "images of death" which took down a process. I
eventually wrote a small HTTP server to distribute tasks and finished the run
of 36475 images in the evening.

417664, 465617, 465553, 465601, 417658: schematics, maybe I can spot them via "illustration"?

1113236 wide format, pass is best

After looking through 200 random images, I didn't see any egregious errors.
-> We're good to go!
